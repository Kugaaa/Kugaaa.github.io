<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/air.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/air.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/air.png">
  <link rel="mask-icon" href="/images/air.png" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-flat-top.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.kugaaa.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":"flat","show_result":true},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":2,"unescape":false,"preload":true}}</script><script src="/js/config.js"></script>

    <meta name="description" content="入门 底层的 LLM 和聊天模型都是无状态的，所以 LangChain 的链式模型和代理模型同样都是无状态的，意味着它们会独立处理每次调用 某些应用程序中，比如聊天机器人，记住先前的交互是至关重要的；LangChain 提供了用于管理和操作以前的聊天消息的辅助工具，这些工具被设计成模块化的，其次 LangChain 提供了将这些工具轻松整合到链式模型中的方法 ChatMessageHi">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain 文档学习 No.5 - 记忆">
<meta property="og:url" content="https://www.kugaaa.com/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86.html">
<meta property="og:site_name" content="贫瘠之地">
<meta property="og:description" content="入门 底层的 LLM 和聊天模型都是无状态的，所以 LangChain 的链式模型和代理模型同样都是无状态的，意味着它们会独立处理每次调用 某些应用程序中，比如聊天机器人，记住先前的交互是至关重要的；LangChain 提供了用于管理和操作以前的聊天消息的辅助工具，这些工具被设计成模块化的，其次 LangChain 提供了将这些工具轻松整合到链式模型中的方法 ChatMessageHi">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.kugaaa.com/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86/%E8%AE%B0%E5%BF%86%E7%B1%BB%E5%9E%8B%E5%A2%9E%E9%95%BF.png">
<meta property="article:published_time" content="2024-01-01T16:00:00.000Z">
<meta property="article:modified_time" content="2024-01-01T16:00:00.000Z">
<meta property="article:author" content="Kuga">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.kugaaa.com/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86/%E8%AE%B0%E5%BF%86%E7%B1%BB%E5%9E%8B%E5%A2%9E%E9%95%BF.png">


<link rel="canonical" href="https://www.kugaaa.com/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86.html">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://www.kugaaa.com/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86.html","path":"开发/开源学习/LangChain/LangChain 文档学习 No.5 - 记忆.html","title":"LangChain 文档学习 No.5 - 记忆"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>LangChain 文档学习 No.5 - 记忆 | 贫瘠之地</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="贫瘠之地" type="application/atom+xml">
<link rel="alternate" href="/rss2.xml" title="贫瘠之地" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">贫瘠之地</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">出来混最重要的是什么？是出来</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%A5%E9%97%A8"><span class="nav-number">1.</span> <span class="nav-text">入门</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#chatmessagehistory"><span class="nav-number">1.1.</span> <span class="nav-text">ChatMessageHistory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#conversationbuffermemory"><span class="nav-number">1.2.</span> <span class="nav-text">ConversationBufferMemory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E9%93%BE%E4%B8%AD%E4%BD%BF%E7%94%A8"><span class="nav-number">1.3.</span> <span class="nav-text">在链中使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%9D%E5%AD%98%E6%B6%88%E6%81%AF%E5%8E%86%E5%8F%B2"><span class="nav-number">1.4.</span> <span class="nav-text">保存消息历史</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%B0%E5%BF%86%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">记忆类型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%86%B2buffer"><span class="nav-number">2.1.</span> <span class="nav-text">缓冲（Buffer）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%93%E5%86%B2%E7%AA%97%E5%8F%A3buffer-window"><span class="nav-number">2.2.</span> <span class="nav-text">缓冲窗口（Buffer Window）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81summary"><span class="nav-number">2.3.</span> <span class="nav-text">摘要（Summary）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B7%B7%E5%90%88buffer-summary"><span class="nav-number">2.4.</span> <span class="nav-text">混合（Buffer Summary）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#token-%E7%BC%93%E5%86%B2token-buffer"><span class="nav-number">2.5.</span> <span class="nav-text">Token 缓冲（Token Buffer）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%9E%E4%BD%93entity"><span class="nav-number">2.6.</span> <span class="nav-text">实体（Entity）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E5%9B%BEknowledge-graph"><span class="nav-number">2.7.</span> <span class="nav-text">知识图（Knowledge Graph）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8vector-store"><span class="nav-number">2.8.</span> <span class="nav-text">向量存储（Vector Store）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.9.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9C%A8-llmchain-%E4%B8%AD%E8%AE%B0%E5%BF%86"><span class="nav-number">3.</span> <span class="nav-text">在 LLMChain 中记忆</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#conversationchain"><span class="nav-number">4.</span> <span class="nav-text">ConversationChain</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BC%9A%E8%AF%9D%E8%AE%B0%E5%BF%86"><span class="nav-number">5.</span> <span class="nav-text">自定义会话记忆</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AE%B0%E5%BF%86"><span class="nav-number">6.</span> <span class="nav-text">自定义记忆</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BB%84%E5%90%88%E8%AE%B0%E5%BF%86"><span class="nav-number">7.</span> <span class="nav-text">组合记忆</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83"><span class="nav-number">8.</span> <span class="nav-text">参考</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Kuga</p>
  <div class="site-description" itemprop="description">欢迎来到知识的荒漠</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">79</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
<script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js"></script>
<div>
  <div style="margin-top:5px">
    <a href="https://github.com/Kugaaa" target="_blank">
      <img alt="Not by AI" src="https://kuga-pic-1258855810.cos.ap-beijing.myqcloud.com/Written-By-Human-Not-By-AI-Badge-white.svg" style="width:auto;height:40px;" title="Not by AI">
    </a>
  </div>

  <div style="margin-top:15px">
    <a href="https://www.foreverblog.cn/go.html" target="_blank">
      <img alt="穿梭虫洞" src="https://img.foreverblog.cn/wormhole_2_tp.gif" style="width:auto;height:38px;" title="穿梭虫洞 - 随机访问十年之约友链博客">
    </a>
  </div>

  <div style="margin-top:10px">
    <a href="https://bjcp.kugaaa.com" target="_blank">
      <img alt="BJCP Hub" src="https://kuga-pic-1258855810.cos.ap-beijing.myqcloud.com/bjcp_hub_logo.png" style="width:auto;height:30px;" title="BJCP Hub">
    </a>
  </div>

  <div style="margin-top:10px;">
    <a target="_blank" href="rss2.xml" style="color:#F99000;font-size:20px;">
      <span class="icon">
        <i class="fa-solid fa-square-rss"></i>
      </span>
      <span>RSS</span>
    </a>
  </div>

  <div style="margin-top:13px">
      <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=370 src="//music.163.com/outchain/player?type=0&id=7776310945&auto=0&height=430"></iframe>
  </div>
</div>
        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.kugaaa.com/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Kuga">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="贫瘠之地">
      <meta itemprop="description" content="欢迎来到知识的荒漠">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="LangChain 文档学习 No.5 - 记忆 | 贫瘠之地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LangChain 文档学习 No.5 - 记忆
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-01-02 00:00:00" itemprop="dateCreated datePublished" datetime="2024-01-02T00:00:00+08:00">2024-01-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E5%8F%91/" itemprop="url" rel="index"><span itemprop="name">开发</span></a>
        </span>
          >
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">开源学习</span></a>
        </span>
          >
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/" itemprop="url" rel="index"><span itemprop="name">LangChain</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="入门">入门</h1>
<p>底层的 LLM 和聊天模型都是无状态的，所以 LangChain
的链式模型和代理模型同样都是无状态的，意味着它们会独立处理每次调用</p>
<p>某些应用程序中，比如聊天机器人，记住先前的交互是至关重要的；LangChain
提供了用于管理和操作以前的聊天消息的辅助工具，这些工具被设计成模块化的，其次
LangChain 提供了将这些工具轻松整合到链式模型中的方法</p>
<h2 id="chatmessagehistory">ChatMessageHistory</h2>
<p>轻量级的包装器，方便保存人类消息、AI 消息，以及获取的方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line">history = ChatMessageHistory()</span><br><span class="line">history.add_user_message(<span class="string">&quot;hi!&quot;</span>)</span><br><span class="line">history.add_ai_message(<span class="string">&quot;whats up?&quot;</span>)</span><br><span class="line"></span><br><span class="line">history.messages</span><br><span class="line"><span class="comment"># &gt;&gt; [HumanMessage(content=&#x27;hi!&#x27;, additional_kwargs=&#123;&#125;),AIMessage(content=&#x27;whats up?&#x27;, additional_kwargs=&#123;&#125;)]</span></span><br></pre></td></tr></table></figure>
<h2 id="conversationbuffermemory">ConversationBufferMemory</h2>
<p><code>ConversationBufferMemory</code> 是
<code>ChatMessageHistory</code> 的一个包装器，可以提取变量中的消息</p>
<p>可以首先将其提取为字符串</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferMemory()</span><br><span class="line">memory.chat_memory.add_user_message(<span class="string">&quot;hi!&quot;</span>)</span><br><span class="line">memory.chat_memory.add_ai_message(<span class="string">&quot;whats up?&quot;</span>)</span><br><span class="line"></span><br><span class="line">memory.load_memory_variables(&#123;&#125;)</span><br><span class="line"><span class="comment"># &gt;&gt;  &#123;&#x27;history&#x27;: &#x27;Human: hi!\nAI: whats up?&#x27;&#125;</span></span><br></pre></td></tr></table></figure>
<p>还可以将历史记录作为消息列表获取</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationBufferMemory(return_messages=<span class="literal">True</span>)</span><br><span class="line">memory.chat_memory.add_user_message(<span class="string">&quot;hi!&quot;</span>)</span><br><span class="line">memory.chat_memory.add_ai_message(<span class="string">&quot;whats up?&quot;</span>)</span><br><span class="line"></span><br><span class="line">memory.load_memory_variables(&#123;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt;&gt;  &#123;&#x27;history&#x27;: [HumanMessage(content=&#x27;hi!&#x27;, additional_kwargs=&#123;&#125;),AIMessage(content=&#x27;whats up?&#x27;, additional_kwargs=&#123;&#125;)]&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="在链中使用">在链中使用</h2>
<p>最后在链中使用它（设置
<code>verbose=True</code>，这样我们就可以看到提示）</p>
<blockquote>
<p>verbose</p>
<p>是否在详细模式下运行，在详细模式下，一些中间日志将打印到控制台</p>
<p>可通过<code>langchain.globals.get_verbose()</code> 访问</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = OpenAI(temperature=<span class="number">0</span>)</span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    memory=ConversationBufferMemory()</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">fir = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;Hello World!&quot;</span>)</span><br><span class="line">sec = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;How to evaluate the world?&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(fir)</span><br><span class="line"><span class="comment"># &gt;&gt; Hello! How can I assist you today?</span></span><br><span class="line"><span class="built_in">print</span>(sec)</span><br><span class="line"><span class="comment"># &gt;&gt; Evaluating the world can be a complex task as it involves considering multiple factors and perspectives. Some common approaches to evaluating the world include assessing the state of the economy, analyzing social and political systems, examining environmental conditions, and evaluating the well-being of individuals and communities. It can also involve considering ethical and moral values, cultural differences, and historical contexts. Ultimately, the process of evaluating the world is subjective and can vary depending on individual beliefs, values, and priorities. Is there any specific aspect of the world you would like to evaluate?</span></span><br></pre></td></tr></table></figure>
<p>因为 <code>verbose</code> 参数，会在过程中输出如下日志</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering new ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line">The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.</span><br><span class="line"></span><br><span class="line">Current conversation:</span><br><span class="line">Human: Hello World!</span><br><span class="line">AI: Hello! How can I assist you today?</span><br><span class="line">Human: How to evaluate the world?</span><br><span class="line">AI:</span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br></pre></td></tr></table></figure>
<h2 id="保存消息历史">保存消息历史</h2>
<p>在使用中，我们可能需要经常保存历史消息，并在后续流程加载和使用</p>
<p>可以通过先将消息转换为普通的 Python 字典，保存这些字典（如 Json
或其他格式），然后加载它们来轻松完成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">history = ChatMessageHistory()</span><br><span class="line">history.add_user_message(<span class="string">&quot;hi!&quot;</span>)</span><br><span class="line">history.add_ai_message(<span class="string">&quot;whats up?&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>转换成字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dicts = messages_to_dict(history.messages)</span><br><span class="line"><span class="built_in">print</span>(dicts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt;&gt; [&#123;&#x27;type&#x27;: &#x27;human&#x27;, &#x27;data&#x27;: &#123;&#x27;content&#x27;: &#x27;hi!&#x27;, &#x27;additional_kwargs&#x27;: &#123;&#125;, &#x27;type&#x27;: &#x27;human&#x27;, &#x27;example&#x27;: False&#125;&#125;, &#123;&#x27;type&#x27;: &#x27;ai&#x27;, &#x27;data&#x27;: &#123;&#x27;content&#x27;: &#x27;whats up?&#x27;, &#x27;additional_kwargs&#x27;: &#123;&#125;, &#x27;type&#x27;: &#x27;ai&#x27;, &#x27;example&#x27;: False&#125;&#125;]</span></span><br></pre></td></tr></table></figure>
<p>字典转换为 message</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">new_messages = messages_from_dict(dicts)</span><br><span class="line"><span class="built_in">print</span>(new_messages)</span><br><span class="line"></span><br><span class="line"><span class="comment"># &gt;&gt;  [HumanMessage(content=&#x27;hi!&#x27;, additional_kwargs=&#123;&#125;),AIMessage(content=&#x27;whats up?&#x27;, additional_kwargs=&#123;&#125;)]</span></span><br></pre></td></tr></table></figure>
<h1 id="记忆类型">记忆类型</h1>
<h2 id="缓冲buffer">缓冲（Buffer）</h2>
<p><code>ConversationBufferMemory</code>
用来存储历史记录，并从中提取历史记录</p>
<p>入门中的示例就是使用 <code>ConversationBufferMemory</code>
来进行实现的</p>
<h2 id="缓冲窗口buffer-window">缓冲窗口（Buffer Window）</h2>
<p><code>ConversationBufferWindowMemory</code>
会在一段时间内保持对话的交互列表，它只使用最后的 K
个交互，这样做的好处是缓冲区就不会变得太大</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferWindowMemory</span><br><span class="line"></span><br><span class="line"><span class="comment"># k = 1，即只使用最后的 1 个交互</span></span><br><span class="line">memory = ConversationBufferWindowMemory(k=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;hi&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;whats up&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;Human: hi\nAI: whats up&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;not much you&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;not much&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;Human: not much you\nAI: not much&#x27;&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="摘要summary">摘要（Summary）</h2>
<p><code>ConversationSummaryMemory</code>
会随着时间的推移创建一份对话总结，有效地从对话中压缩信息</p>
<p>摘要记忆将对话进行总结并将总结内容存储在记忆中，然后可以将此记忆用于将迄今为止的对话摘要注入到提示或者链中；此记忆对于较长的对话非常有用，如果在提示中保存所有的历史消息将会占用太多
token</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationSummaryMemory, ChatMessageHistory</span><br><span class="line"><span class="keyword">from</span> langchain.llms <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line">memory = ConversationSummaryMemory(</span><br><span class="line">    llm=chat_model, </span><br><span class="line">    return_messages=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;hi&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;whats up&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: [SystemMessage(content=&#x27;The human greets the AI with &quot;Hello World!&quot; and the AI responds with &quot;Yes!&quot;&#x27;)]&#125;</span></span><br></pre></td></tr></table></figure>
<p>也可以直接调用 <code>predict_new_summary</code> 方法，传入 message
集合，直接获取摘要内容</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">messages = memory.chat_memory.messages</span><br><span class="line">previous_summary = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="built_in">print</span>(memory.predict_new_summary(messages, previous_summary))</span><br><span class="line"><span class="comment"># &gt;&gt; The human greets the AI with &quot;Hello World!&quot; and the AI responds with &quot;Yes!&quot;</span></span><br></pre></td></tr></table></figure>
<p>可以选择使用以前生成的摘要来加快初始化速度，并通过直接初始化来避免重新生成摘要</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationSummaryMemory(</span><br><span class="line">    llm=chat_module,</span><br><span class="line">    <span class="comment"># 这里的 buffer 构造参数用于初始化</span></span><br><span class="line">    buffer=<span class="string">&quot;The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.&quot;</span>,</span><br><span class="line">    chat_memory=history,</span><br><span class="line">    return_messages=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="混合buffer-summary">混合（Buffer Summary）</h2>
<p><code>ConversationSummaryBufferMemory</code>
结合了缓冲和摘要两种特点，保留了最近交互的缓冲信息，但它不只是完全刷新旧的交互数据，而是将它们同时总结为摘要</p>
<p>通过 <code>max_token_limit</code>
这个参数进行实现的，当最新的对话文字长度在参数范围之内的时候，LangChain
会记忆原始对话内容；当对话文字超出了这个参数的长度，那么模型就会把所有超过预设长度的内容进行总结，以节省
Token 数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=<span class="number">10</span>)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;hi&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;whats up&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;not much you&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;not much&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;&#125;))</span><br></pre></td></tr></table></figure>
<p>这里没有成功调用，因为 Azure 的 gpt-35-turbo-16k 模型还没有实现 token
相关的 <code>get_num_tokens_from_messages</code> 方法（详见
langchain.chat_models.openai.ChatOpenAI.get_num_tokens_from_messages）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> NotImplementedError(</span><br><span class="line">        <span class="string">f&quot;get_num_tokens_from_messages() is not presently implemented &quot;</span></span><br><span class="line">        <span class="string">f&quot;for model <span class="subst">&#123;model&#125;</span>.&quot;</span></span><br><span class="line">        <span class="string">&quot;See https://github.com/openai/openai-python/blob/main/chatml.md for &quot;</span></span><br><span class="line">        <span class="string">&quot;information on how messages are converted to tokens.&quot;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>这里摘录一下极客时间相关课程的示例，感受下 buffer 和 summary
的共同作用</p>
<hr />
<p>第一回合输出</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;我姐姐明天要过生日，我需要一束生日花束。&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;history&#x27;<span class="punctuation">:</span> &#x27;&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;response&#x27;<span class="punctuation">:</span> &#x27; 哇，你姐姐要过生日啊！那太棒了！我建议你去买一束色彩鲜艳的花束，因为这样可以代表你给她的祝福和祝愿。你可以去你家附近的花店，或者也可以从网上订购，你可以看看有没有特别的花束，比如彩色玫瑰或者百合花，它们会更有特色。&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>第二回合的输出</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;她喜欢粉色玫瑰，颜色是粉色的。&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;history&#x27;<span class="punctuation">:</span> &#x27;Human<span class="punctuation">:</span> 我姐姐明天要过生日，我需要一束生日花束。\nAI<span class="punctuation">:</span>  哇，你姐姐要过生日啊！那太棒了！我建议你去买一束色彩鲜艳的花束，因为这样可以代表你给她的祝福和祝愿。你可以去你家附近的花店，或者也可以从网上订购，你可以看看有没有特别的花束，比如彩色玫瑰或者百合花，它们会更有特色。&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;response&#x27;<span class="punctuation">:</span> &#x27; 好的，那粉色玫瑰就是一个很好的选择！你可以买一束粉色玫瑰花束，这样你姐姐会很开心的！你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品&#x27;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>第三回合的输出</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span>&#x27;input&#x27;<span class="punctuation">:</span> &#x27;我又来了，还记得我昨天为什么要来买花吗？&#x27;<span class="punctuation">,</span></span><br><span class="line">&#x27;history&#x27;<span class="punctuation">:</span> <span class="string">&quot;System: \nThe human asked the AI for advice on buying a bouquet for their sister&#x27;s birthday. The AI suggested buying a vibrant bouquet as a representation of their wishes and blessings, and recommended looking for special bouquets like colorful roses or lilies for something more unique.\nHuman: 她喜欢粉色玫瑰，颜色是粉色的。\nAI:  好的，那粉色玫瑰就是一个很好的选择！你可以买一束粉色玫瑰花束，这样你姐姐会很开心的！你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品&quot;</span><span class="punctuation">,</span></span><br><span class="line">&#x27;response&#x27;<span class="punctuation">:</span> &#x27; 是的，我记得你昨天来买花是为了给你姐姐的生日。你想买一束粉色玫瑰花束来表达你的祝福和祝愿，你可以在花店里找到粉色玫瑰，也可以从网上订购，你可以根据你的预算，选择合适的数量。另外，你可以考虑添加一些装饰，比如细绳、彩带或者小礼品<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>不难看出在第二回合，记忆机制完整地记录了第一回合的对话，但是在第三回合，它察觉出前两轮的对话已经超出了设置的
token 数量（示例中设置的是 300），就把早期的对话加以总结，以节省 token
资源</p>
<p><code>ConversationSummaryBufferMemory</code>
的优势是通过总结可以回忆起较早的互动，而且有缓冲区确保我们不会错过最近的互动信息，当然对于较短的对话，<code>ConversationSummaryBufferMemory</code>
也可能会增加 token 数量</p>
<h2 id="token-缓冲token-buffer">Token 缓冲（Token Buffer）</h2>
<p><code>ConversationTokenBufferMemory</code>，在记忆中保留最近交互的互动缓冲，并使用
token 长度而不是交互次数来确定何时刷新交互</p>
<p>个人认为类似缓冲窗口，但是这个记忆类型是根据 token
长度判断丢弃哪些内容，即窗口滑动的标准是 token 长度</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=<span class="number">10</span>)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;hi&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;whats up&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;not much you&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;not much&quot;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;&#125;))</span><br></pre></td></tr></table></figure>
<p>这个操作同样依赖 <code>get_num_tokens_from_messages</code>
方法，暂时无法实现</p>
<h2 id="实体entity">实体（Entity）</h2>
<p><code>ConversationEntityMemory</code>
会记忆关于会话中特定实体的给定事实</p>
<p>它提取关于实体的信息（通过使用
LLM），并随着时间的推移积累关于该实体的知识（也通过使用 LLM）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationEntityMemory(llm=Azure.chat_model)</span><br><span class="line">_<span class="built_in">input</span> = &#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;Deven &amp; Sam are working on a hackathon project&quot;</span>&#125;</span><br><span class="line"><span class="comment"># 这里生成新的 entity key</span></span><br><span class="line">memory.load_memory_variables(_<span class="built_in">input</span>)</span><br><span class="line"><span class="comment"># 这里会对 entity 进行总结</span></span><br><span class="line">memory.save_context(</span><br><span class="line">    _<span class="built_in">input</span>,</span><br><span class="line">    &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot; That sounds like a great project! What kind of project are they working on?&quot;</span>&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&#x27;The relation between Deven and Sam?&#x27;</span>&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;Human: Deven &amp; Sam are working on a hackathon project\nAI:  That sounds like a great project! What kind of project are they working on?&#x27;, &#x27;entities&#x27;: &#123;&#x27;Deven&#x27;: &#x27;Deven is currently working on a hackathon project with Sam.&#x27;, &#x27;Sam&#x27;: &#x27;Sam is working on a hackathon project with Deven.&#x27;&#125;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&#x27;What is Sam doing?&#x27;</span>&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;Human: Deven &amp; Sam are working on a hackathon project\nAI:  That sounds like a great project! What kind of project are they working on?&#x27;, &#x27;entities&#x27;: &#123;&#x27;Sam&#x27;: &#x27;Sam is working on a hackathon project with Deven.&#x27;&#125;&#125;</span></span><br></pre></td></tr></table></figure>
<p>上面的例子可以看出来，当话题和两个人相关时
<code>The relation between Deven and Sam?</code>，记忆会总结并同时返回
Deven 和 Sam 的信息；当话题只和 Sam 有关时
<code>What is Sam doing?</code>，则只会返回 Sam 的实体信息</p>
<h2 id="知识图knowledge-graph">知识图（Knowledge Graph）</h2>
<p><code>ConversationKGMemory</code> 使用知识图来重新创建记忆</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">llm = Azure.chat_model</span><br><span class="line">memory = ConversationKGMemory(llm=llm)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;say hi to Sam&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;who is Sam&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;Sam is a friend&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;okay&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;Sam and Deven are my teachers&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;okay,I known&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;Deven has a white watch&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;okay&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;who is sam&quot;</span>&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;On Sam: Sam is a person. Sam is a friend. Sam is my teacher.\nOn Deven: Deven is my teacher. Deven has white watch.&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;who is Deven&quot;</span>&#125;))</span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;On Deven: Deven is my teacher. Deven has white watch.&#x27;&#125;</span></span><br></pre></td></tr></table></figure>
<p>和实体类似，都是使用 LLM 对内容进行概括和匹配</p>
<h2 id="向量存储vector-store">向量存储（Vector Store）</h2>
<p><code>VectorStoreRetrieverMemory</code>
将记忆存储在向量存储中，并在每次调用时查询前 K 个最匹配的文档</p>
<p>与大多数其他记忆类不同的是，它<strong>不明确跟踪交互的顺序</strong>，”文档“是历史的对话片段，有助于帮助
AI 了解早期历史的内容</p>
<p><strong>初始化向量存储工具</strong></p>
<p>取决于所使用的向量存储工具</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> faiss</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain.docstore <span class="keyword">import</span> InMemoryDocstore</span><br><span class="line"><span class="keyword">from</span> langchain.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"></span><br><span class="line">embedding_size = <span class="number">1536</span> <span class="comment"># OpenAIEmbeddings 的维度</span></span><br><span class="line">index = faiss.IndexFlatL2(embedding_size)</span><br><span class="line">embedding_fn = OpenAIEmbeddings().embed_query</span><br><span class="line">vectorstore = FAISS(embedding_fn, index, InMemoryDocstore(&#123;&#125;), &#123;&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>创建 VectorStoreRetrieverMemory</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在实际使用中，您可以将参数 k 设置得更高，但我们使用 k=1 来展示向量查找仍然返回语义相关的信息</span></span><br><span class="line">retriever = vectorstore.as_retriever(search_kwargs=<span class="built_in">dict</span>(k=<span class="number">1</span>))</span><br><span class="line">memory = VectorStoreRetrieverMemory(retriever=retriever)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当添加到代理程序时，内存对象可以保存来自对话或使用工具的相关信息</span></span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;My favorite food is pizza&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;that&#x27;s good to know&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;My favorite sport is soccer&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;...&quot;</span>&#125;)</span><br><span class="line">memory.save_context(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;I don&#x27;t the Celtics&quot;</span>&#125;, &#123;<span class="string">&quot;output&quot;</span>: <span class="string">&quot;ok&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>使用</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;<span class="string">&quot;prompt&quot;</span>: <span class="string">&quot;what sport should i watch?&quot;</span>&#125;)[<span class="string">&quot;history&quot;</span>])</span><br><span class="line"><span class="comment"># &gt;&gt; input: My favorite sport is soccer\noutput: ...</span></span><br></pre></td></tr></table></figure>
<h2 id="总结">总结</h2>
<p>因为实体、向量等类型是后续版本提供的，这里只进行基础的四种记忆类型的总结</p>
<table>
<colgroup>
<col style="width: 27%" />
<col style="width: 32%" />
<col style="width: 39%" />
</colgroup>
<thead>
<tr>
<th style="text-align: left;">类型</th>
<th style="text-align: left;">优点</th>
<th style="text-align: left;">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ConversationBufferMemory（缓冲）</td>
<td style="text-align: left;">提供完整信息；简单、直观</td>
<td style="text-align: left;">使用更多
token，提高响应时间和成本；对话可能超出 token 限制</td>
</tr>
<tr>
<td
style="text-align: left;">ConversationBufferWindowMemory（缓冲窗口）</td>
<td style="text-align: left;">token 使用量较小；窗口灵活</td>
<td style="text-align: left;">无法记录早期互动；窗口可能设置不合理</td>
</tr>
<tr>
<td style="text-align: left;">ConversationSummaryMemory（摘要）</td>
<td style="text-align: left;">对于长对话减少 token
使用；允许进行更长时间的对话</td>
<td style="text-align: left;">短对话反而增加 token
的使用；对话记忆取决于 LLM 的总结能力；总结时会使用额外的 token</td>
</tr>
<tr>
<td
style="text-align: left;">ConversationSummaryBufferMemory（混合）</td>
<td
style="text-align: left;">能够回忆起早期互动；不会错过最近消息；灵活性高</td>
<td style="text-align: left;">短对话反而增加 token
的使用；存储原始活动也会增加 token 的使用</td>
</tr>
</tbody>
</table>
<p>不同记忆类型交互数量和 token 数量增长统计图</p>
<img src="/%E5%BC%80%E5%8F%91/%E5%BC%80%E6%BA%90%E5%AD%A6%E4%B9%A0/LangChain/LangChain%20%E6%96%87%E6%A1%A3%E5%AD%A6%E4%B9%A0%20No.5%20-%20%E8%AE%B0%E5%BF%86/%E8%AE%B0%E5%BF%86%E7%B1%BB%E5%9E%8B%E5%A2%9E%E9%95%BF.png" class="" title="记忆类型增长">
<h1 id="在-llmchain-中记忆">在 LLMChain 中记忆</h1>
<p>如何将记忆类和 <code>LLMChain</code>
一起使用，<strong>关键在于正确设置提示</strong></p>
<p>在下面的提示中，我们有两个输入键：一个用于实际输入，另一个用于记忆类的输入，需要注意，我们要确保
<code>PromptTemplate</code> 和 <code>ConversationBufferMemory</code>
中的键匹配（chat_history）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">template = <span class="string">&quot;&quot;&quot;You are a chatbot having a conversation with a human.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;chat_history&#125;</span></span><br><span class="line"><span class="string">Human: &#123;human_input&#125;</span></span><br><span class="line"><span class="string">Chatbot:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;chat_history&quot;</span>, <span class="string">&quot;human_input&quot;</span>], template=template</span><br><span class="line">)</span><br><span class="line">memory = ConversationBufferMemory(memory_key=<span class="string">&quot;chat_history&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">llm = OpenAI()</span><br><span class="line">llm_chain = LLMChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    memory=memory,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">llm_chain.predict(human_input=<span class="string">&quot;Hi there my friend&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>聊天模型同理</p>
<h1 id="conversationchain">ConversationChain</h1>
<p><code>ConversationChain</code> 是 <code>LLMChain</code>
的子类，最主要的特点是它提供了包含 AI
前缀和人类前缀的对话摘要格式，这个对话格式和记忆机制结合得非常紧密</p>
<p>看一下 <code>ConversationChain</code> 内置的模板</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化对话链</span></span><br><span class="line">conv_chain = ConversationChain(llm=llm)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印对话的模板</span></span><br><span class="line"><span class="built_in">print</span>(conv_chain.prompt.template)</span><br></pre></td></tr></table></figure>
<p>输出</p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">The following <span class="keyword">is</span> a friendly conversation <span class="keyword">between</span> a human <span class="keyword">and</span> an AI. The AI <span class="keyword">is</span> talkative <span class="keyword">and</span> provides lots <span class="keyword">of</span> specific details <span class="keyword">from</span> <span class="keyword">its</span> context. If <span class="keyword">the</span> AI <span class="keyword">does</span> <span class="keyword">not</span> know <span class="keyword">the</span> answer <span class="keyword">to</span> a question, <span class="keyword">it</span> truthfully says <span class="keyword">it</span> <span class="keyword">does</span> <span class="keyword">not</span> know.</span><br><span class="line"></span><br><span class="line">Current conversation:</span><br><span class="line">&#123;history&#125;</span><br><span class="line">Human: &#123;input&#125;</span><br><span class="line">AI:</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这个提示试图通过说明以下内容来减少幻觉，也就是尽量减少模型编造的信息：</p>
<ul>
<li>如果 AI 不知道问题的答案，它就会如实说它不知道</li>
<li>两个参数会通过提示模板传递给 LLM，我们希望返回的输出只是对话的延续
<ul>
<li>{history} 存储会话记忆</li>
<li>{input} 设置新的输入</li>
</ul></li>
</ul>
<p>当有了 <code>&#123;history&#125;</code> 参数，以及 Human 和 AI
这两个前缀，我们就能够把历史对话信息存储在提示模板中，并作为新的提示内容在新一轮的对话过程中传递给
LLM，这就是记忆机制的原理</p>
<h1 id="自定义会话记忆">自定义会话记忆</h1>
<p>上面介绍了 <code>ConversationChain</code>
将以对话形式格式化历史记录并生成提示，依赖所用的记忆类，AI 默认前缀为
<code>AI</code>，人类的默认前缀为 <code>Human</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConversationBufferMemory</span>(<span class="title class_ inherited__">BaseChatMemory</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Buffer for storing conversation memory.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    human_prefix: <span class="built_in">str</span> = <span class="string">&quot;Human&quot;</span></span><br><span class="line">    ai_prefix: <span class="built_in">str</span> = <span class="string">&quot;AI&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>可以自定义进行前缀的修改</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># AI 前缀修改为 AI Assistant</span></span><br><span class="line">memory = ConversationBufferMemory(ai_prefix=<span class="string">&quot;AI Assistant&quot;</span>)</span><br><span class="line"><span class="comment"># 人类前缀修改为 Friend</span></span><br><span class="line">memory = ConversationBufferMemory(human_prefix=<span class="string">&quot;Friend&quot;</span>)</span><br><span class="line"></span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    prompt=PROMPT,</span><br><span class="line">    llm=llm,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    memory=memory,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h1 id="自定义记忆">自定义记忆</h1>
<p>已经存在一些预定义类型的记忆，也可以实现自定义的记忆类</p>
<p>通过继承 <code>BaseMemory</code> 来实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FavoriteFoodMemory</span>(<span class="title class_ inherited__">BaseMemory</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Memory class for storing information about entities.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Define dictionary to store information about entities.</span></span><br><span class="line">    entities: <span class="built_in">dict</span> = &#123;&#125;</span><br><span class="line">    <span class="comment"># Define key to pass information about entities into prompt.</span></span><br><span class="line">    memory_key: <span class="built_in">str</span> = <span class="string">&quot;entities&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">clear</span>(<span class="params">self</span>):</span><br><span class="line">        self.entities = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">memory_variables</span>(<span class="params">self</span>) -&gt; <span class="type">List</span>[<span class="built_in">str</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Define the variables we are providing to the prompt.&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> [self.memory_key]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">load_memory_variables</span>(<span class="params">self, inputs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>]</span>) -&gt; <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Load the memory variables, in this case the entity key.&quot;&quot;&quot;</span></span><br><span class="line">        s = <span class="string">&quot;&quot;</span></span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> self.entities.items():</span><br><span class="line">            s += (value + <span class="string">&quot;\n&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> &#123;self.memory_key: s&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_context</span>(<span class="params">self, inputs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="type">Any</span>], outputs: <span class="type">Dict</span>[<span class="built_in">str</span>, <span class="built_in">str</span>]</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Save context from this conversation to buffer.&quot;&quot;&quot;</span></span><br><span class="line">        pattern = <span class="string">r&quot;My favorite food is (\w+)&quot;</span></span><br><span class="line">        <span class="keyword">for</span> key, value <span class="keyword">in</span> inputs.items():</span><br><span class="line">            matches = re.findall(pattern, value)</span><br><span class="line">            num_matches = <span class="built_in">len</span>(matches)</span><br><span class="line">            <span class="keyword">if</span> num_matches &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">match</span> = re.search(pattern, value)</span><br><span class="line">                food_name = <span class="keyword">match</span>.group(<span class="number">1</span>)</span><br><span class="line">                self.entities[key] = food_name</span><br></pre></td></tr></table></figure>
<p>这里实现了一个简单的类，用于获取用户喜欢吃的食物</p>
<ul>
<li>定义了记忆中变量 name，为 <code>entities</code></li>
<li>load_memory_variables 方法获取 entities
保存的喜好，拼装成字符串输出</li>
<li>save_context 通过正则 <code>r"My favorite food is (\w+)</code>
匹配用户的食物喜好并保存</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">template = <span class="string">&quot;&quot;&quot;You are a chef, directly output the dish name you want to make based on user preferences.</span></span><br><span class="line"><span class="string">Don&#x27;t continue asking questions.</span></span><br><span class="line"><span class="string">Do not reply to questions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">User Preferences:</span></span><br><span class="line"><span class="string">&#123;entities&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Conversation:</span></span><br><span class="line"><span class="string">Human: &#123;input&#125;</span></span><br><span class="line"><span class="string">AI:&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># prompt，让 AI 扮演一个厨师</span></span><br><span class="line">prompt = PromptTemplate(input_variables=[<span class="string">&quot;entities&quot;</span>, <span class="string">&quot;input&quot;</span>], template=template)</span><br><span class="line"><span class="comment"># 自定义记忆类</span></span><br><span class="line">custom_memory = FavoriteFoodMemory()</span><br><span class="line"><span class="comment"># 模拟记忆类事先保存了互动，提取过用户的喜好食物</span></span><br><span class="line">custom_memory.save_context(&#123;<span class="string">&#x27;input&#x27;</span>: <span class="string">&#x27;My favorite food is banana.&#x27;</span>&#125;, &#123;<span class="string">&#x27;output&#x27;</span>: <span class="string">&#x27;Greate!&#x27;</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 ConversationChain</span></span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=Azure.chat_model, prompt=prompt, verbose=<span class="literal">True</span>, memory=custom_memory</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>使用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(conversation.run(<span class="string">&quot;I&#x27;m hungry.&quot;</span>))</span><br><span class="line"><span class="comment"># &gt;&gt; Banana Split</span></span><br></pre></td></tr></table></figure>
<p>过程中日志，可以看到正确地选择了记忆，并格式化到提示中</p>
<figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt; Entering <span class="built_in">new</span> ConversationChain chain...</span><br><span class="line">Prompt after formatting:</span><br><span class="line">You are a chef, directly output the dish name you want <span class="keyword">to</span> make based <span class="keyword">on</span> user preferences.</span><br><span class="line">Don<span class="comment">&#x27;t continue asking questions.</span></span><br><span class="line"><span class="keyword">Do</span> <span class="built_in">not</span> reply <span class="keyword">to</span> questions.</span><br><span class="line"></span><br><span class="line">User Preferences:</span><br><span class="line">banana</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="symbol">Conversation:</span></span><br><span class="line"><span class="symbol">Human:</span> I<span class="comment">&#x27;m hungry.</span></span><br><span class="line"><span class="symbol">AI:</span></span><br><span class="line"></span><br><span class="line">&gt; Finished chain.</span><br></pre></td></tr></table></figure>
<h1 id="组合记忆">组合记忆</h1>
<p>可以在同一个链中使用多个记忆类，要组合多个记忆类需要初始化并使用
<code>CombinedMemory</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缓冲记忆</span></span><br><span class="line">conv_memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history_lines&quot;</span>, input_key=<span class="string">&quot;input&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 摘要记忆</span></span><br><span class="line">summary_memory = ConversationSummaryMemory(llm=Azure.chat_model, input_key=<span class="string">&quot;input&quot;</span>)</span><br><span class="line"><span class="comment"># 通过 CombinedMemory 组合</span></span><br><span class="line">memory = CombinedMemory(memories=[conv_memory, summary_memory])</span><br><span class="line">_DEFAULT_TEMPLATE = <span class="string">&quot;&quot;&quot;The following is a friendly conversation between a human and an AI. </span></span><br><span class="line"><span class="string">The AI is talkative and provides lots of specific details from its context. </span></span><br><span class="line"><span class="string">If the AI does not know the answer to a question, it truthfully says it does not know.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Summary of conversation:</span></span><br><span class="line"><span class="string">&#123;history&#125;</span></span><br><span class="line"><span class="string">Current conversation:</span></span><br><span class="line"><span class="string">&#123;chat_history_lines&#125;</span></span><br><span class="line"><span class="string">Human: &#123;input&#125;</span></span><br><span class="line"><span class="string">AI:&quot;&quot;&quot;</span></span><br><span class="line">PROMPT = PromptTemplate(</span><br><span class="line">    input_variables=[<span class="string">&quot;history&quot;</span>, <span class="string">&quot;input&quot;</span>, <span class="string">&quot;chat_history_lines&quot;</span>],</span><br><span class="line">    template=_DEFAULT_TEMPLATE,</span><br><span class="line">)</span><br><span class="line"><span class="comment"># ConversationChain</span></span><br><span class="line">conversation = ConversationChain(llm=Azure.chat_model, verbose=<span class="literal">True</span>, memory=memory, prompt=PROMPT)</span><br></pre></td></tr></table></figure>
<p>执行查看结果</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">conversation.run(<span class="string">&quot;Hi&quot;</span>)</span><br><span class="line"></span><br><span class="line">pprint(conversation.memory.memories[<span class="number">0</span>].load_memory_variables(&#123;&#125;))</span><br><span class="line"><span class="comment"># 这里是组合的 ConversationBufferMemory</span></span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;chat_history_lines&#x27;: &#x27;Human: Hi\nAI: Hello! How can I assist you today?&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line">pprint(conversation.memory.memories[<span class="number">1</span>].load_memory_variables(&#123;&#125;))</span><br><span class="line"><span class="comment"># 这里是组合的 ConversationSummaryMemory</span></span><br><span class="line"><span class="comment"># &gt;&gt; &#123;&#x27;history&#x27;: &#x27;The human greets the AI and the AI asks how it can assist the human.&#x27;&#125;</span></span><br></pre></td></tr></table></figure>
<h1 id="参考">参考</h1>
<p><a
target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/memory/types/vectorstore_retriever_memory">Backed
by a Vector Store | 🦜️🔗 Langchain</a></p>
<p><a
target="_blank" rel="noopener" href="https://python.langchain.com.cn/docs/modules/memory/types/vectorstore_retriever_memory">支持向量存储
| 🦜️🔗 Langchain</a></p>
<p><a
target="_blank" rel="noopener" href="https://time.geekbang.org/column/intro/100617601?utm_campaign=geektime_search&amp;utm_content=geektime_search&amp;utm_medium=geektime_search&amp;utm_source=geektime_search&amp;utm_term=geektime_search">LangChain
实战课 (geekbang.org)</a></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/AI/" rel="tag"><i class="fa fa-tag"></i> AI</a>
              <a href="/tags/LangChain/" rel="tag"><i class="fa fa-tag"></i> LangChain</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/%E5%BC%80%E5%8F%91/DB/MySQL/MySQL%205.7%20%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%20-%20InnoDB%20%E5%BC%95%E6%93%8E.html" rel="prev" title="MySQL 5.7 官方文档 - InnoDB 引擎.md">
                  <i class="fa fa-angle-left"></i> MySQL 5.7 官方文档 - InnoDB 引擎.md
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/%E5%BC%80%E5%8F%91/DB/Vector/%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93.html" rel="next" title="简单了解向量数据库">
                  简单了解向量数据库 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-solid fa-user-secret"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Kuga</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/kugaaa" class="github-corner" title="在 GitHub 上关注我" aria-label="在 GitHub 上关注我" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"default","dark":"dark"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.0/mermaid.min.js","integrity":"sha256-G8ouPAnw4zzMbnAenHnVz6h9XpKbNdOkrqTh7AadyHs="}}</script>
  <script src="/js/third-party/tags/mermaid.js"></script>


  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>


  





</body>
</html>
